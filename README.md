### Модель GAN на основе классов TensorFlow.
За основу была взята [документация TensorFlow](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit#wrapping_up_an_end-to-end_gan_example).<br>
Но с изменениями. Целью было разобраться в построении моделей на классах TensorFlow. Поэтому код обильно комментирован.

**Комментарий к модели.**

Для последовательной тренировки генератора и дискриминатора, необходимо подавать наборы данных в виде мини-пакетов (mini-batches). Проще всего это было сделать с помощью метода [dataset.from_tensor_slices](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices).

Использование этого подхода резко сокращает код и улучшает его читабельность. И увеличивает скорость выполнения.

После того, как мы решили задачу подготовки и подачи данных, переходим к построению модели.

Генератор и дискриминатор определены в отдельных функциях - геттерах. Можно было бы их реализовать как методы класса **Model**, но смысла нет. Также в таком варианте нет необходимости их компилировать отдельно.

При реализации модели на основе класса TensorFlow есть возможность кастомизировать различные фазы построения модели. Для практической реализации модели **GAN** на основе классов было бы вполне достаточно переопределить фазу .**FIT (метод train_step)**, однако было интересно понять, какие есть возможности при переопределении и других фаз.

В фазе **.COMPILE** можно определить отдельно для генератора и дискриминатора оптимизаторы, функции потерь и метрики.

**.compile(optimizers=optimizers, loss=loss, metrics=metrics)**

В качестве параметров для компиляции передаем словари с оптимизаторами, функциями потерь и метриками
**Оптимизаторы в виде словаря** (они могут быть различными для генератора и дискриминатора): 
```
optimizers = {
    "discriminator_optimizer": Adam(learning_rate=learning_rate),
    "generator_optimizer": RMSprop(learning_rate=learning_rate)}
```
**Словари для функций loss**.<br> Функция **Loss** может быть одинаковой для генератора и дискриминатора, но в некоторых случаях (**CGAN**) могут потребоваться и разные функции для них, поэтому оставляем в коде такую возможность.
Можно в качестве значения передать стандартную **TensorFlow** функцию, а можно и свою собственную.<br>
Для задачи **бинарной классификации** (у нас именно такая задача) будем использовать 
```tf.keras.losses.BinaryCrossentropy(from_logits= ХХ, ..)```
которая вычисляет кросс-энтропию между истинными лэйблами и предсказанными.<br>
```BinaryCrossentropy``` имеет параметр ```from_logits=False/True```.<br>
Если ```from_logits=False```, то предсказанное значение (y_pred) представляет собой вероятность, область значений [0,1].<br>
Если ```from_logits=True```, то предсказанное значение (y_pred) представляет лоджит (logit), область значений [-inf, + inf].<br>
Для оценки качества работы дискриминатора, мы сравниваем предсказанные им значения лейблов с истинными значениями.<br>
Дискриминатор имеет фукцию активации **sigmoid**, область значения которой **[0,1]**.<br>
Значения лейблов также лежат в области **[0,1]**.<br>
Для оценки качества работы генератора, мы передаем выданные им изображения в генератор, который выдает оценку, область значения которой **[0,1]**.<br>
С этой точки зрения, правильнее использовать **from_logits=True**, однако **документация TensorFlow** настоятельно рекомендует использовать вариант с **from_logits=True**.<br>
Поэтому в нашем случае для генератора и дискриминатора будем использовать параметр **from_logits=True**<br>
```loss = {
  "generator_loss_fn": tf.keras.losses.BinaryCrossentropy(from_logits=False), 
  "discriminator_loss_fn": tf.keras.losses.BinaryCrossentropy(from_logits=False)}```<br>
Для передачи в класс собственной функции потерь, можно передать предварительно определенную функцию таким образом: **"custom_loss_fn": my_loss_fn()**<br>
**Метрики передаем также в виде словаря.**<br>
В словаре можно в качестве значения передать стандартную **TensorFlow** метрику, а можно и свою собственную.<br>
Для собственных метрик, если требуется контроль метрик только для батча, можно обойтись просто определением функции<br>
```def metric_function(y_true, y_pred):
    ...
    metric_value =```<br>
Если требуется контроль метрик по всему датасету (то есть, за эпоху), собственную метрику нужно определять на основе класса<br>
```class MetricLayer(tf.keras.metrics.Metric)
    def __init__(self, name="MetricLayer", **kwargs):
        super(MetricLayer, self).__init__(name=name, **kwargs)
        self.metric = self.add_weight(name="Metric", initializer="zeros") ```<br>
и далее, определяем переменные треккеров:<br>```
loss_tracker = tf.keras.metrics.Mean(name="loss")
mae = tf.keras.metrics.MeanAbsoluteError(name="mae")
metrics = {"generator_loss": metric_fn, "discriminator_loss": tf.keras.metrics.Accuracy()}```
###Фаза FIT подробно откомментирована в коде
**Пример инициализации своего класса:**
```gan = MyGan(image_shape=(28,28,1), generator_type='strong', disciminator_type='weak', class_vector_shape, latent_dim=100)```<br>
**latent_dim** - размер вектора скрытого пространства, из которого создается изображение генератором
